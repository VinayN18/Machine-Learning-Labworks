# -*- coding: utf-8 -*-
"""B21AI023_Lab_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GGfsHr8OLhM_axHI49Uvp0XA0L7n6Fq2

## **QUESTION 1**
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

# Importing data from google drive
dataset = pd.read_csv('/content/drive/MyDrive/prml/lab-3/titanic.csv')
dataset.head()

dataset.info()

dataset.describe()

#checking the empty values
dataset.isnull()
sns.heatmap(dataset.isnull(),yticklabels=False,cbar=False)
'''Cream Lines in the graph indicates the empty values'''

#Visualising number of people survived based on gender
sns.countplot(x='Survived',hue='Sex',data=dataset)

#Visualising number of people survived based on Pclass
sns.countplot(x='Survived',hue='Pclass',data=dataset)

#Histogram visualisation of people of different age in Titanic
dataset['Age'].plot.hist(bins=30)

#Histogram Visualisation of Fare paid by the people
dataset['Fare'].hist(bins=40)

#Visualisation of Embarkment of people
sns.countplot(x='Embarked',data=dataset)

#Filling the missing data
##Filling the AGE column based on the average age of the persons from different pclass
result = dataset.groupby('Pclass')['Age'].mean()
print("Mean of ages based on",result)

##Function to fill the missing age data based on Pclass
def fill_age(col):
  age = col[0]
  pclass= col[1]
  if pd.isnull(age):
    if pclass==1:
      return 38.233441
    elif pclass==2:
      return 29.877630
    else:
      return 25.140620
  else:
    return age

# #calling the function and filling the missing values 
dataset['Age'] = dataset[['Age','Pclass']].apply(fill_age,axis=1)

#Plotting heatmap
sns.heatmap(dataset.isnull(),yticklabels=False,cbar=False)
'''Cream lines indicate missing values'''

##Dropping the Cabin column since there are so many null values
dataset.drop('Cabin',axis=1,inplace=True)
dataset.head()

sns.heatmap(dataset.isnull(),yticklabels=False,cbar=False)
'''Dataset is clean there are no more missing values'''

##Converting the string values of a column into dummy values of 0 and 1
gender = pd.get_dummies(dataset['Sex'],drop_first=True)
embark = pd.get_dummies(dataset['Embarked'],drop_first=True)
pclass = pd.get_dummies(dataset['Pclass'],drop_first=True)

##Adding these new columns to the dataset
dataset = pd.concat([dataset,gender,embark,pclass],axis=1)
dataset.head()

##Dropping the columns
dataset.drop(['Sex','Embarked','Name','Ticket','PassengerId','Pclass'],axis=1,inplace=True)
dataset.head()

'''Data Preprocessing is completed and dropping of the un-used columns 
is also completed and we can now split our dataset into train and test sets'''

##Splitting data into train and test sets
X = dataset.drop('Survived',axis=1)
y = dataset['Survived']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

dataset.info()
dataset.head()

"""### **Identifying the best variant of Naive Bayes Classifier**

There are three variants of Naive Bayes Classifiers we can choose for classification:


*   Gaussian Naive Bayes: Continuous Features

*   Bernoulli Naive Bayes: Binary Features

*   Multinomial Naive Bayes: Categorical Features
"""

## Naive Bayes Classification
from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB
from sklearn.metrics import accuracy_score

##Calculating the accuracy with Gaussian Naive Bayes Classifier
gaussian_nb = GaussianNB()
gaussian_nb.fit(X_train, y_train) #Training the model using the training data sets
y_pred_gaussian = gaussian_nb.predict(X_test) #Predict the response for test dataset
accuracy_gaussian = accuracy_score(y_test, y_pred_gaussian)
print("Gaussian Naive Bayes Classifier Accuracy:", accuracy_gaussian)

##Calculating the accuracy with Multinomial Naive Bayes Classifier
multinomial_nb = MultinomialNB()
multinomial_nb.fit(X_train, y_train)
y_pred_multinomial = multinomial_nb.predict(X_test)
accuracy_multinomial = accuracy_score(y_test, y_pred_multinomial)
print("\nMultinomial Naive Bayes Classifier Accuracy:", accuracy_multinomial)

##Calculating the accuracy with Bernoulli Naive Bayes Classifier
bernoulli_nb = BernoulliNB()
bernoulli_nb.fit(X_train, y_train)
y_pred_bernoulli = bernoulli_nb.predict(X_test)
accuracy_bernoulli = accuracy_score(y_test, y_pred_bernoulli)
print("\nBernoulli Naive Bayes Classifier Accuracy:", accuracy_bernoulli)
print("\n")

"""### After calculating the accuracy with all the three naive bayes classifiers we get the highest accuracy from the Gaussian Naive Bayes Classifier

### Therefore, the best possible variant of the Naive Bayes Classifier for the dataset is **Gaussian Naive Bayes Classifeir**
"""

##Making the confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred_gaussian)
print("Confusion matrix\n",cm)

"""### **Plotting the curve (ROC and AUC)**"""

from sklearn.metrics import roc_curve, auc

#Predicting the probabilities of class for each instance in test dataset 
y_prob = gaussian_nb.predict_proba(X_test)

#Computing the false positive rate, true positive rate and threshold
fpr, tpr, thresholds = roc_curve(y_test, y_prob[:, 1])
print("\nArea under ROC Curve is: ",auc(fpr,tpr))
#Plotting the ROC curve
plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))
plt.plot([0, 1], [0, 1], linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Gaussian Naive Bayes Classifier')
plt.legend(loc="upper left")
plt.show()

"""### **Performing 5 fold cross-validation**"""

from sklearn.model_selection import KFold,cross_val_score

scores_nb = np.array(cross_val_score(gaussian_nb, X_train, y_train, cv=5))
print("Mean Validation NB Score: ",np.mean(scores_nb))
print("Variance in NB validation Score: ",np.var(scores_nb),'\n\n')


kfold = KFold(n_splits=5, random_state=None, shuffle=True)

#Initializing a list to store the accuracy results
accuracy_results = []

#Copying the data in an array
dataset_copy = np.array(X)

#Looping through each fold
for train_index, test_index in kfold.split(dataset_copy):
  x_train, x_test = dataset_copy[train_index], dataset_copy[test_index]
  Y_train, Y_test = y[train_index], y[test_index]

  #Training the Gaussian Naive Bayes Classifier
  model = GaussianNB()
  model.fit(x_train, Y_train)

  #Making predictions on test data
  Y_predictions = model.predict(x_test)
  p = model.predict(x_test)[1]
  q = model.predict(x_test)[0]
  #Calculating accuracy score
  acc = accuracy_score(Y_test, Y_predictions)

  #Appending the accuracy score to the results list
  accuracy_results.append(acc)
    
  #Compute the probability of the top class
  probability = model.predict_proba(x_test)
  top_class = np.argmax(probability, axis=1)  
  # top_class_prob = probability[np.arange(len(probability)), top_class]
  print("First ten predictions",top_class[:10])
  print("Actual Classes: ",np.array(Y_test)[:10])
  print("Accuracy: ",accuracy_score(np.array(Y_test)[:10], top_class[:10]))
  print("Average Cofidence of top class: ",np.mean(probability),"\n")

print("Accuracy results for 5 fold Cross-validation\n",accuracy_results)
# Calculating the average accuracy across all folds
average_accuracy = np.mean(accuracy_results)
print("\nAverage accuracy:", average_accuracy,'\n\n')

"""### **Contour plots with data points to visualize the class-conditional densities**"""

# Plot the class-conditional densities for Age and Fare
sns.kdeplot(dataset[dataset['Survived'] == 0]['Age'], dataset[dataset['Survived'] == 0]['Fare'], cmap="Reds", shade=True, shade_lowest=False)
sns.kdeplot(dataset[dataset['Survived'] == 1]['Age'], dataset[dataset['Survived'] == 1]['Fare'], cmap="Blues", shade=True, shade_lowest=False)

# Add the data points to the plot
sns.scatterplot(x='Age', y='Fare', hue='Survived', data=dataset)

# Label the plot
plt.xlabel('Age')
plt.ylabel('Fare')
plt.title('Class-conditional densities for Age and Fare')

# Show the plot
plt.show()

"""### **Comparison with Decision Tree Classifier**"""

from sklearn.tree import DecisionTreeClassifier as DTC
dtc_classifier = DTC()
scores_dt = cross_val_score(dtc_classifier, X_train, y_train, cv=5)
print("Mean Validation DT Score: ",np.mean(scores_dt))
print("Variance in DT validation Score: ",np.var(scores_dt))


kfold_dt = KFold(n_splits=5, random_state=None, shuffle=True)

#Initializing a list to store the accuracy results
accuracy_results_dt = []

#Copying the data in an array
dataset_copy_dt = np.array(X)

#Looping through each fold
for train_index_dt, test_index_dt in kfold_dt.split(dataset_copy_dt):
  x_train_dt, x_test_dt = dataset_copy_dt[train_index_dt], dataset_copy_dt[test_index_dt]
  Y_train_dt, Y_test_dt = y[train_index_dt], y[test_index_dt]

  #Training the Gaussian Naive Bayes Classifier
  model_dt = DTC()
  model_dt.fit(x_train_dt, Y_train_dt)

  #Making predictions on test data
  Y_predictions_dt = model_dt.predict(x_test_dt)

  #Calculating accuracy score
  acc_dt = accuracy_score(Y_test_dt, Y_predictions_dt)

  #Appending the accuracy score to the results list
  accuracy_results_dt.append(acc_dt)

print("Accuracy results for 5 fold Cross-validation\n",accuracy_results_dt)

# Calculating the average accuracy across all folds
average_accuracy_dt = np.mean(accuracy_results_dt)
print("\nAverage accuracy of Decision Tree:", average_accuracy_dt,'\n\n')

"""# **QUESTION 2**

### **Histogram to plot the distribution of samples**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

dataset2 = pd.read_csv("/content/drive/MyDrive/prml/lab-3/dataset (1).csv")
dataset2.head()

dataset2.info()

dataset2.hist(bins=25, figsize=(20,20))

for col in dataset2.columns:
  if col != "Y":
    sns.histplot(data=dataset2, x=col, hue='Y',element='step')
    plt.show()

"""### **Calculating the Prior Probability for all classes**"""

one_cnt = 0
two_cnt = 0
three_cnt = 0
for i in dataset2['Y']:
  if i==1:
    one_cnt += 1
  elif i==2:
    two_cnt += 1
  elif i==3:
    three_cnt += 1 

print("Count of class 1 in Y: ",one_cnt)
print("Count of class 2 in Y: ",two_cnt)
print("Count of class 3 in Y: ",three_cnt)
print("\nPrior probability of class 1: ", one_cnt/len(dataset2['Y']))
print("Prior probability of class 2: ", two_cnt/len(dataset2['Y']))
print("Prior probability of class 3: ", three_cnt/len(dataset2['Y']))

"""###  **Discretize the features into bins**"""

def discretize_feature(feature, n_bins):
    # Calculate minimum and maximum value
    feature_min = np.min(feature)
    feature_max = np.max(feature)
    bin_width = (feature_max - feature_min) / n_bins
    
    # Discretize feature
    bins = [feature_min + i * bin_width for i in range(n_bins + 1)]
    discretized_feature = [int(round((value - feature_min) / bin_width)) for value in feature]
    
    return discretized_feature

for f in dataset2.drop('Y',axis=1):
  dataset2[f] = discretize_feature(np.array(dataset2[f]),5)

print(dataset2)

"""###  **Determining the likelihood/class conditional probabilities**"""

def calculate_class_probabilities(data,target):
    class_pro = {}
    uniClasses = np.unique(target)
    print(uniClasses)

    for col in data.columns:
      uniFeatures = data[col].value_counts()
      
    for cls in uniClasses:
        class_indices = np.where(target == cls)
        # print(class_indices)
        class_data = data[class_indices]
        # print(class_data)
        # print(data.shape[1])
        for feature in range(data.shape[1]):
            # print(feature)
            values, counts = np.unique(class_data[:, feature], return_counts=True)
            total = np.sum(counts)
            for value, count in zip(values, counts):
                class_pro[cls][feature][value] = count / total

    return class_pro

"""### **Plotting count of each unique element for each class**"""

for col in dataset2.columns:
  if(col=='Y'):
    continue
  counts = {}
  for label in np.unique(dataset2['Y']):
    counts[label] = {}
    for element in np.unique(dataset2[col]):
        counts[label][element] = len(np.where((dataset2[col] == element) & (dataset2['Y'] == label))[0])

  # Plot the count of each unique element for each class
  for label, count_dict in counts.items():
    plt.bar(count_dict.keys(), count_dict.values(), alpha=0.5, label=f"Class {label}")

  plt.legend()
  plt.xlabel(col)
  plt.ylabel("Count")
  plt.title("Count of Each Unique Element for Each Class")
  plt.show()